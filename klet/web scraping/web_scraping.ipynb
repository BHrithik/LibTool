{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import urllib.parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = Options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_service = Service(ChromeDriverManager().install())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(service=chrome_service, options=chrome_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../web scraping/libwebscraping.json'\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_titles = []\n",
    "\n",
    "for entry in data:\n",
    "    # Assuming each entry is a dictionary and has a key 'workTitle'\n",
    "    if 'workTitle' in entry:\n",
    "        work_titles.append(entry['workTitle'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(filename='selenium_debug.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_worldcat(search_title):\n",
    "    driver = webdriver.Chrome()  # or the driver you are using\n",
    "    encoded_title = urllib.parse.quote_plus(search_title.strip())\n",
    "    search_url = f\"https://search.worldcat.org/search?q={encoded_title}\"\n",
    "    driver.get(search_url)\n",
    "    logging.debug(f\"Navigating to URL: {search_url}\")\n",
    "\n",
    "    try:\n",
    "        # Wait for the search results to be present\n",
    "        wait = WebDriverWait(driver, 30)\n",
    "        all_results = wait.until(EC.presence_of_all_elements_located((By.XPATH, \"//a[contains(@data-testid, 'title-')]\")))\n",
    "\n",
    "        # Check if the first result matches the search title\n",
    "        if all_results:\n",
    "            first_result = all_results[0]\n",
    "            first_result_title = first_result.text.strip().lower()\n",
    "            logging.debug(f\"First search result title: {first_result_title}\")\n",
    "\n",
    "            if search_title.strip().lower() == first_result_title:\n",
    "                first_result.click()\n",
    "\n",
    "                # Extract the dynamic part from the URL\n",
    "                current_url = driver.current_url\n",
    "                dynamic_part = current_url.split('/')[-1]\n",
    "\n",
    "                # Wait for the subject information to load\n",
    "                subject_selector = f\"span[aria-labelledby='subject-{dynamic_part}']\"\n",
    "                WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, subject_selector)))\n",
    "                soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "                # Find the parent span element and then extract all a tags within it\n",
    "                subject_container = soup.select_one(subject_selector)\n",
    "                subject_elements = subject_container.find_all(\"a\", class_=\"MuiTypography-root\")\n",
    "                subjects = [element.get_text() for element in subject_elements]\n",
    "\n",
    "                return subjects\n",
    "            else:\n",
    "                logging.debug(f\"The first result does not match the search title: {search_title}\")\n",
    "        else:\n",
    "            logging.debug(\"No search results found.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error processing the search result:\", e)\n",
    "        logging.exception(\"Error processing the search result\")\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subjects for Your Paradise : ['Corée du Sud Conditions sociales Romans, nouvelles, etc', 'Fiction', 'Korea (South)', 'Korea (South) Social conditions Fiction', 'Leprosy Patients', 'Leprosy Patients Korea (South)', 'Lépreux Corée du Sud', 'Romans', 'Social conditions']\n"
     ]
    }
   ],
   "source": [
    "title = \"Your Paradise\"\n",
    "subjects = search_worldcat(title)\n",
    "if subjects:\n",
    "    print(\"Subjects for\", title, \":\", subjects)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
